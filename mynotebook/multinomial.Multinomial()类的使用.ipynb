{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "概率基础学习中，multinomial包中Multinomial类的使用方法"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a20427efbbee4d49"
  },
  {
   "cell_type": "markdown",
   "source": [
    "该类接收四个参数：multinomial.Multinomial(total_count=1, probs=None, logits=None, validate_args=None)\n",
    "- total_count 指单次抽样中样本的个数，int型\n",
    "- probs 指各个事件发生的概率，tensor型，可传入概率也可以传入频数（我理解的就是事件共发生的次数），可以通过props属性查看概率分布"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "957b0e89fc3a4d68"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667])\n",
      "tensor([0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.distributions import multinomial\n",
    "fair_probs = torch.ones(6) / 6 #传入概率\n",
    "fair_probs_c = torch.ones(6) #频数\n",
    "x = multinomial.Multinomial(1, fair_probs).probs\n",
    "y = multinomial.Multinomial(1, fair_probs_c).probs\n",
    "print(x)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T09:23:50.412792Z",
     "start_time": "2023-11-14T09:23:50.406942Z"
    }
   },
   "id": "acab819553b2719e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- logits 指各个事件概率的自然对数 tensor型，同样可以传概率的自然对数和频数的自然对数\n",
    "- valid_args 指是否检查参数的合法性，默认True，在手动设置为False后，也会检查参数的合法性\n",
    "**注意：probs和logits不能同时传入，也不能都不传入，否则会报错**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe39c8944f989e04"
  },
  {
   "cell_type": "markdown",
   "source": [
    "sample()是Mlutinomial类的一个抽象函数，唯一传参为(sample_shape=torch.Size())，用来指定抽样的次数，默认抽样一次，输出一个形状为(len(probs))的张量，否则输出((sample_shape, len(probs)))\n",
    "**samele((a, b))的sample_shape参数的意思是抽样a组，每一组抽样b次，如下代码中给sample传入了(5, 3)大小的抽样形状，输出为(5， 3， 6)的一个三维张量**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb5feac899d1bde3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 1.],\n",
      "         [0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0., 0.],\n",
      "         [0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "fair_probs = torch.ones(6) / 6 #传入概率\n",
    "x = multinomial.Multinomial(1, fair_probs).sample((5, 3))\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T09:35:43.076823Z",
     "start_time": "2023-11-14T09:35:43.063549Z"
    }
   },
   "id": "c397bf51b32afdaf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "通过命令查看包中的函数和类的官方内容："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78ed9a02c1ce065"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__text_signature__']\n"
     ]
    }
   ],
   "source": [
    "print(dir(torch.multinomial))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T13:22:11.871234Z",
     "start_time": "2023-11-14T13:22:11.865508Z"
    }
   },
   "id": "86882b4c52740fc6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看特定函数和类的用法："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "905ec84552736e39"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Multinomial in module torch.distributions.multinomial:\n",
      "\n",
      "class Multinomial(torch.distributions.distribution.Distribution)\n",
      " |  Multinomial(total_count=1, probs=None, logits=None, validate_args=None)\n",
      " |  \n",
      " |  Creates a Multinomial distribution parameterized by :attr:`total_count` and\n",
      " |  either :attr:`probs` or :attr:`logits` (but not both). The innermost dimension of\n",
      " |  :attr:`probs` indexes over categories. All other dimensions index over batches.\n",
      " |  \n",
      " |  Note that :attr:`total_count` need not be specified if only :meth:`log_prob` is\n",
      " |  called (see example below)\n",
      " |  \n",
      " |  .. note:: The `probs` argument must be non-negative, finite and have a non-zero sum,\n",
      " |            and it will be normalized to sum to 1 along the last dimension. :attr:`probs`\n",
      " |            will return this normalized value.\n",
      " |            The `logits` argument will be interpreted as unnormalized log probabilities\n",
      " |            and can therefore be any real number. It will likewise be normalized so that\n",
      " |            the resulting probabilities sum to 1 along the last dimension. :attr:`logits`\n",
      " |            will return this normalized value.\n",
      " |  \n",
      " |  -   :meth:`sample` requires a single shared `total_count` for all\n",
      " |      parameters and samples.\n",
      " |  -   :meth:`log_prob` allows different `total_count` for each parameter and\n",
      " |      sample.\n",
      " |  \n",
      " |  Example::\n",
      " |  \n",
      " |      >>> # xdoctest: +SKIP(\"FIXME: found invalid values\")\n",
      " |      >>> m = Multinomial(100, torch.tensor([ 1., 1., 1., 1.]))\n",
      " |      >>> x = m.sample()  # equal probability of 0, 1, 2, 3\n",
      " |      tensor([ 21.,  24.,  30.,  25.])\n",
      " |  \n",
      " |      >>> Multinomial(probs=torch.tensor([1., 1., 1., 1.])).log_prob(x)\n",
      " |      tensor([-4.1338])\n",
      " |  \n",
      " |  Args:\n",
      " |      total_count (int): number of trials\n",
      " |      probs (Tensor): event probabilities\n",
      " |      logits (Tensor): event log probabilities (unnormalized)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Multinomial\n",
      " |      torch.distributions.distribution.Distribution\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, total_count=1, probs=None, logits=None, validate_args=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  entropy(self)\n",
      " |      Returns entropy of distribution, batched over batch_shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tensor of shape batch_shape.\n",
      " |  \n",
      " |  expand(self, batch_shape, _instance=None)\n",
      " |      Returns a new distribution instance (or populates an existing instance\n",
      " |      provided by a derived class) with batch dimensions expanded to\n",
      " |      `batch_shape`. This method calls :class:`~torch.Tensor.expand` on\n",
      " |      the distribution's parameters. As such, this does not allocate new\n",
      " |      memory for the expanded distribution instance. Additionally,\n",
      " |      this does not repeat any args checking or parameter broadcasting in\n",
      " |      `__init__.py`, when an instance is first created.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch_shape (torch.Size): the desired expanded size.\n",
      " |          _instance: new instance provided by subclasses that\n",
      " |              need to override `.expand`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          New distribution instance with batch dimensions expanded to\n",
      " |          `batch_size`.\n",
      " |  \n",
      " |  log_prob(self, value)\n",
      " |      Returns the log of the probability density/mass function evaluated at\n",
      " |      `value`.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (Tensor):\n",
      " |  \n",
      " |  sample(self, sample_shape=torch.Size([]))\n",
      " |      Generates a sample_shape shaped sample or sample_shape shaped batch of\n",
      " |      samples if the distribution parameters are batched.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  logits\n",
      " |  \n",
      " |  mean\n",
      " |      Returns the mean of the distribution.\n",
      " |  \n",
      " |  param_shape\n",
      " |  \n",
      " |  probs\n",
      " |  \n",
      " |  support\n",
      " |      Returns a :class:`~torch.distributions.constraints.Constraint` object\n",
      " |      representing this distribution's support.\n",
      " |  \n",
      " |  variance\n",
      " |      Returns the variance of the distribution.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'total_count': <class 'int'>}\n",
      " |  \n",
      " |  arg_constraints = {'logits': IndependentConstraint(Real(), 1), 'probs'...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  cdf(self, value: torch.Tensor) -> torch.Tensor\n",
      " |      Returns the cumulative density/mass function evaluated at\n",
      " |      `value`.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (Tensor):\n",
      " |  \n",
      " |  enumerate_support(self, expand: bool = True) -> torch.Tensor\n",
      " |      Returns tensor containing all values supported by a discrete\n",
      " |      distribution. The result will enumerate over dimension 0, so the shape\n",
      " |      of the result will be `(cardinality,) + batch_shape + event_shape`\n",
      " |      (where `event_shape = ()` for univariate distributions).\n",
      " |      \n",
      " |      Note that this enumerates over all batched tensors in lock-step\n",
      " |      `[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\n",
      " |      along dim 0, but with the remaining batch dimensions being\n",
      " |      singleton dimensions, `[[0], [1], ..`.\n",
      " |      \n",
      " |      To iterate over the full Cartesian product use\n",
      " |      `itertools.product(m.enumerate_support())`.\n",
      " |      \n",
      " |      Args:\n",
      " |          expand (bool): whether to expand the support over the\n",
      " |              batch dims to match the distribution's `batch_shape`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tensor iterating over dimension 0.\n",
      " |  \n",
      " |  icdf(self, value: torch.Tensor) -> torch.Tensor\n",
      " |      Returns the inverse cumulative density/mass function evaluated at\n",
      " |      `value`.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (Tensor):\n",
      " |  \n",
      " |  perplexity(self) -> torch.Tensor\n",
      " |      Returns perplexity of distribution, batched over batch_shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tensor of shape batch_shape.\n",
      " |  \n",
      " |  rsample(self, sample_shape: torch.Size = torch.Size([])) -> torch.Tensor\n",
      " |      Generates a sample_shape shaped reparameterized sample or sample_shape\n",
      " |      shaped batch of reparameterized samples if the distribution parameters\n",
      " |      are batched.\n",
      " |  \n",
      " |  sample_n(self, n: int) -> torch.Tensor\n",
      " |      Generates n samples or n batches of samples if the distribution\n",
      " |      parameters are batched.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  set_default_validate_args(value: bool) -> None\n",
      " |      Sets whether validation is enabled or disabled.\n",
      " |      \n",
      " |      The default behavior mimics Python's ``assert`` statement: validation\n",
      " |      is on by default, but is disabled if Python is run in optimized mode\n",
      " |      (via ``python -O``). Validation may be expensive, so you may want to\n",
      " |      disable it once a model is working.\n",
      " |      \n",
      " |      Args:\n",
      " |          value (bool): Whether to enable validation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  batch_shape\n",
      " |      Returns the shape over which parameters are batched.\n",
      " |  \n",
      " |  event_shape\n",
      " |      Returns the shape of a single sample (without batching).\n",
      " |  \n",
      " |  mode\n",
      " |      Returns the mode of the distribution.\n",
      " |  \n",
      " |  stddev\n",
      " |      Returns the standard deviation of the distribution.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  has_enumerate_support = False\n",
      " |  \n",
      " |  has_rsample = False\n"
     ]
    }
   ],
   "source": [
    "help(multinomial.Multinomial)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T13:23:58.994052Z",
     "start_time": "2023-11-14T13:23:58.973777Z"
    }
   },
   "id": "bb4854138590e3ed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
